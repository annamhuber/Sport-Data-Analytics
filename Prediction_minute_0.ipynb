{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "#\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('./Data/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('./Data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = load_obj('matchdata_19_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['match_id','game_len','radiant_win','radiant1_hero_id','radiant1_kills','radiant1_deaths','radiant1_assists','radiant1_denies','radiant1_gold','radiant1_lh','radiant1_xp','radiant1_level','radiant1_creeps_stacked','radiant1_camps_stacked','radiant1_rune_pickups','radiant1_firstblood_claimed','radiant1_towers_killed','radiant1_roshans_killed','radiant1_obs_placed','radiant1_sen_placed','radiant2_hero_id','radiant2_kills','radiant2_deaths','radiant2_assists','radiant2_denies','radiant2_gold','radiant2_lh','radiant2_xp','radiant2_level','radiant2_creeps_stacked','radiant2_camps_stacked','radiant2_rune_pickups','radiant2_firstblood_claimed','radiant2_towers_killed','radiant2_roshans_killed','radiant2_obs_placed','radiant2_sen_placed','radiant3_hero_id','radiant3_kills','radiant3_deaths','radiant3_assists','radiant3_denies','radiant3_gold','radiant3_lh','radiant3_xp','radiant3_level','radiant3_creeps_stacked','radiant3_camps_stacked','radiant3_rune_pickups','radiant3_firstblood_claimed','radiant3_towers_killed','radiant3_roshans_killed','radiant3_obs_placed','radiant3_sen_placed','radiant4_hero_id','radiant4_kills','radiant4_deaths','radiant4_assists','radiant4_denies','radiant4_gold','radiant4_lh','radiant4_xp','radiant4_level','radiant4_creeps_stacked','radiant4_camps_stacked','radiant4_rune_pickups','radiant4_firstblood_claimed','radiant4_towers_killed','radiant4_roshans_killed','radiant4_obs_placed','radiant4_sen_placed','radiant5_hero_id','radiant5_kills','radiant5_deaths','radiant5_assists','radiant5_denies','radiant5_gold','radiant5_lh','radiant5_xp','radiant5_level','radiant5_creeps_stacked','radiant5_camps_stacked','radiant5_rune_pickups','radiant5_firstblood_claimed','radiant5_towers_killed','radiant5_roshans_killed','radiant5_obs_placed','radiant5_sen_placed','dire1_hero_id','dire1_kills','dire1_deaths','dire1_assists','dire1_denies','dire1_gold','dire1_lh','dire1_xp','dire1_level','dire1_creeps_stacked','dire1_camps_stacked','dire1_rune_pickups','dire1_firstblood_claimed','dire1_towers_killed','dire1_roshans_killed','dire1_obs_placed','dire1_sen_placed','dire2_hero_id','dire2_kills','dire2_deaths','dire2_assists','dire2_denies','dire2_gold','dire2_lh','dire2_xp','dire2_level','dire2_creeps_stacked','dire2_camps_stacked','dire2_rune_pickups','dire2_firstblood_claimed','dire2_towers_killed','dire2_roshans_killed','dire2_obs_placed','dire2_sen_placed','dire3_hero_id','dire3_kills','dire3_deaths','dire3_assists','dire3_denies','dire3_gold','dire3_lh','dire3_xp','dire3_level','dire3_creeps_stacked','dire3_camps_stacked','dire3_rune_pickups','dire3_firstblood_claimed','dire3_towers_killed','dire3_roshans_killed','dire3_obs_placed','dire3_sen_placed','dire4_hero_id','dire4_kills','dire4_deaths','dire4_assists','dire4_denies','dire4_gold','dire4_lh','dire4_xp','dire4_level','dire4_creeps_stacked','dire4_camps_stacked','dire4_rune_pickups','dire4_firstblood_claimed','dire4_towers_killed','dire4_roshans_killed','dire4_obs_placed','dire4_sen_placed','dire5_hero_id','dire5_kills','dire5_deaths','dire5_assists','dire5_denies','dire5_gold','dire5_lh','dire5_xp','dire5_level','dire5_creeps_stacked','dire5_camps_stacked','dire5_rune_pickups','dire5_firstblood_claimed','dire5_towers_killed','dire5_roshans_killed','dire5_obs_placed','dire5_sen_placed'])\n",
    "for match in data:\n",
    "    entry=[]\n",
    "    entry.append(match[\"match_id\"])\n",
    "    entry.append(match[\"duration\"])\n",
    "    entry.append(match[\"radiant_win\"])\n",
    "    for player in match[\"players\"]:\n",
    "        entry.append(player['hero_id'])\n",
    "        entry.append(player['kills'])\n",
    "        entry.append(player['deaths'])\n",
    "        entry.append(player['assists'])\n",
    "        entry.append(player['denies'])\n",
    "        entry.append(player['gold_per_min'])\n",
    "        entry.append(player['last_hits'])\n",
    "        entry.append(player['xp_per_min'])\n",
    "        entry.append(player['level'])\n",
    "        entry.append(player['creeps_stacked'])\n",
    "        entry.append(player['camps_stacked'])\n",
    "        entry.append(player['rune_pickups'])\n",
    "        entry.append(player['firstblood_claimed'])\n",
    "        entry.append(player['towers_killed'])\n",
    "        entry.append(player['roshans_killed'])\n",
    "        entry.append(player['obs_placed'])\n",
    "        entry.append(player['sen_placed'])\n",
    "\n",
    "\n",
    "\n",
    "    df.loc[len(df)] = entry\n",
    "\n",
    "save_obj(df,\"cleaned_df_matchdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Working DF\n",
    "\n",
    "df_loaded = load_obj(\"cleaned_df_matchdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_heroes = df_loaded[['match_id','radiant_win','radiant1_hero_id','radiant2_hero_id','radiant3_hero_id','radiant4_hero_id','radiant5_hero_id','dire1_hero_id','dire2_hero_id','dire3_hero_id','dire4_hero_id','dire5_hero_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_heroes = df_heroes.astype('int64')\n",
    "df_cleaned = df_heroes.drop(columns=[\"radiant_win\"])\n",
    "df_targets = df_heroes[['match_id','radiant_win']]\n",
    "df_cleaned.set_index(\"match_id\", inplace = True)\n",
    "df_targets.set_index(\"match_id\", inplace = True)\n",
    "# df_cleaned.reset_index(level=0, inplace=True)\n",
    "\n",
    "print(f'Number of samples in cleaned df: {df_cleaned.shape[0]}')\n",
    "print(f'Number of columns in cleaned df: {df_cleaned.shape[1]}')\n",
    "\n",
    "for col in df_cleaned.columns:\n",
    "    if df_cleaned[col].isnull().any():\n",
    "        print(col, df_cleaned[col].isnull().sum())\n",
    "\n",
    "X = df_cleaned #.drop(columns=[\"radiant_win\",\"next_roshan_team\"])\n",
    "y = df_targets\n",
    "# X.reset_index(drop=True, inplace=True)\n",
    "# y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=12)\n",
    "print(f'Number of samples in train: {X_train.shape[0]}')\n",
    "print(f'Number of columns in train: {X_train.shape[1]}')\n",
    "\n",
    "print(f'Number of samples in test: {X_test.shape[0]}')\n",
    "print(f'Number of columns in test: {X_test.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hero_list = pd.read_json('Data/heroes.json').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hero_names = df_hero_list[['id','localized_name']]\n",
    "df_hero_names.set_index(\"id\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_list = []\n",
    "\n",
    "for index, row in X.iterrows():\n",
    "    for x in row:\n",
    "        heroes_list.append(x)\n",
    "    \n",
    "print('heroes list length: ', len(heroes_list))\n",
    "\n",
    "\n",
    "df_heroes = pd.DataFrame(heroes_list)\n",
    "picks = df_heroes[0].value_counts()\n",
    "\n",
    "df_heroes = df_hero_names.join(picks, how = \"outer\")\n",
    "df_heroes.columns = ['Hero Name', 'Number Picks']\n",
    "df_heroes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train['game_len'], bins=40, label='Train');\n",
    "plt.hist(X_test['game_len'], bins=40, label='Test');\n",
    "plt.title('Distribution of game time');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes.plot.bar(figsize=(30,10), x='Hero Name', y='Number Picks', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_sorted = df_heroes.sort_values(by=['Number Picks'])\n",
    "smallest = df_heroes.nsmallest(10, 'Number Picks')\n",
    "greatest = df_heroes.nlargest(10, 'Number Picks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest.plot.bar(x='Hero Name', y='Number Picks', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greatest.plot.bar(x='Hero Name', y='Number Picks', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_heroes = []\n",
    "looser_heroes = []\n",
    "for index, match in df_loaded.iterrows():\n",
    "    if match[0]:\n",
    "        for element in match.iloc[1:6]:\n",
    "            winner_heroes.append(element)\n",
    "        for element in match.iloc[6:11]:\n",
    "            looser_heroes.append(element)\n",
    "    else:\n",
    "        for element in match.iloc[6:11]:\n",
    "            winner_heroes.append(element)\n",
    "        for element in match.iloc[1:6]:\n",
    "            looser_heroes.append(element)\n",
    "\n",
    "print('Winners: ', len(winner_heroes))\n",
    "print('Loosers: ', len(looser_heroes))\n",
    "\n",
    "df_winner_heroes = pd.DataFrame(winner_heroes) \n",
    "df_looser_heroes = pd.DataFrame(looser_heroes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_wins = df_winner_heroes[0].value_counts()\n",
    "number_losses = df_looser_heroes[0].value_counts()\n",
    "\n",
    "df_number_wins = number_wins.to_frame()\n",
    "df_number_wins.columns = ['Wins']\n",
    "df_number_losses = number_losses.to_frame()\n",
    "df_number_losses.columns = ['Losses']\n",
    "\n",
    "\n",
    "df_heroes_with_score = df_heroes.join(df_number_wins, how = \"outer\")\n",
    "df_heroes_with_score = df_heroes_with_score.join(df_number_losses, how = \"outer\")\n",
    "df_heroes_with_score['Winrate'] = df_heroes_with_score['Wins']/(df_heroes_with_score['Number Picks'])\n",
    "df_heroes_with_score.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_with_score.plot.bar(figsize=(30,10), x='Hero Name', y='Winrate', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_with_score_sorted = df_heroes_with_score.sort_values(by=['Winrate'])\n",
    "df_heroes_with_score_smallest = df_heroes_with_score.nsmallest(10, 'Winrate')\n",
    "df_heroes_with_score_greatest = df_heroes_with_score.nlargest(10, 'Winrate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_with_score_smallest.plot.bar(x='Hero Name', y='Winrate', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_with_score_greatest.plot.bar(x='Hero Name', y='Winrate', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heroes_with_score.plot.scatter(x='Number Picks', y='Winrate', rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "radiant_win,dire_win=y_train[\"radiant_win\"].value_counts()\n",
    "\n",
    "labels = ['Win Rate']\n",
    "men_means = [radiant_win]\n",
    "women_means = [dire_win]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Radiant')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Dire')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Number of Wins')\n",
    "ax.set_title('Win rate by side')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, solver='lbfgs', max_iter=500,\n",
    "                           random_state=17, n_jobs=4,\n",
    "                          multi_class='multinomial')\n",
    "logit_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                       ('logit', logit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "# this may take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logit_val_pred = logit_pipe.predict(X_test)\n",
    "accuracy_score(y_test, logit_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "first_forest = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=17, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "first_forest.fit(X_train, y_train)\n",
    "# this may take a while... (17ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest_val_pred = first_forest.predict(X_test)\n",
    "accuracy_score(y_test, forest_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(first_forest.feature_importances_,\n",
    "             index=X_train.columns, columns=['Importance']).sort_values(\n",
    "    by='Importance', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, lgb_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 stage of hyper-param tuning: tuning model complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'num_leaves': [7, 15, 31, 63],\n",
    "              'max_depth': [3, 4, 5, 6, -1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_searcher = GridSearchCV(estimator=lgb_clf, param_grid=param_grid,\n",
    "                             cv=5, verbose=1, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_searcher.fit(X_train, y_train) # This may take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_searcher.best_params_, grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, grid_searcher.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 stage of hyper-param tuning: convergence:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'learning_rate': 0.046415888336127774} 0.5101333992768946\n",
      "0.5220742817098809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   10.5s finished\n"
     ]
    }
   ],
   "source": [
    "# This may take a while\n",
    "num_iterations = 200\n",
    "lgb_clf2 = LGBMClassifier(random_state=17, max_depth=5,\n",
    "                          num_leaves=15, n_estimators=num_iterations,\n",
    "                          n_jobs=1)\n",
    "\n",
    "param_grid2 = {'learning_rate': np.logspace(-3, 0, 10)}\n",
    "grid_searcher2 = GridSearchCV(estimator=lgb_clf2, param_grid=param_grid2,\n",
    "                               cv=5, verbose=1, n_jobs=4)\n",
    "grid_searcher2.fit(X_train, y_train)\n",
    "print(grid_searcher2.best_params_, grid_searcher2.best_score_)\n",
    "print(accuracy_score(y_test, grid_searcher2.predict(X_test)))\n",
    "# This may take very long !!! 6.3 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_lgb = LGBMClassifier(n_estimators=200, num_leaves=15,\n",
    "                           learning_rate=0.05, max_depth=5,\n",
    "                         n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 260 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=5, n_estimators=200, n_jobs=4,\n",
       "               num_leaves=15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "final_lgb.fit(X_train, y_train)\n",
    "# This may take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_final_pred = final_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5202055594487269\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, lgb_final_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
